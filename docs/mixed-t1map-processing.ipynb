{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f2e235c",
   "metadata": {},
   "source": [
    "# Mixed IR/SE\n",
    "This document attempts to describe the procedure for estimation of $T_1$-time within cerebrospinal fluid based on the interleaved inversion-recovery, spin-echo (Mixed IR/SE) MRI-data for fast $T_1$-time estimates within cerebrospinal fluid (CSF).\n",
    "Note that these steps are further detailed in the article [https://doi.org/10.1101/2025.07.19.25331835], which is related to the work done for the Gonzo data record.\n",
    "\n",
    "The steps include:\n",
    "- Converting necessary volumes from enhanced DICOM to Nifti.\n",
    "- Running FreeSurfer on a pre-contrast $T_1$-weighted image --- potentially supported by either FLAIR or a $T_2$-weighted image --- for the purpose of extrapolating FreeSurfer brain segmentations to the CSF-space.\n",
    "- Estimating the $T_1$-time by using a lookup-table for the ratio between the inversion recovery and spin-echo signal.\n",
    "- Registering the Mixed IR/SE images to the reference space of the pre-contrast $T_1$-weighted image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d774d8",
   "metadata": {},
   "source": [
    "**Data**:\n",
    "\n",
    "To replicate the processing steps of the accompanying article, you need the following data for each subject, (with `ses` representing the session):\n",
    "- `mri_dataset/sub-01/ses-01/anat/sub-01_ses-01_T1w.nii.gz`\n",
    "- `mri_dataset/sub-01/$ses/mixed/sub-01_${ses}_acq-mixed_IR-corrected-real.nii.gz`\n",
    "- `mri_dataset/sub-01/$ses/mixed/sub-01_${ses}_acq-mixed_SE-modulus.nii.gz`\n",
    "- `mri_dataset/sub-01/$ses/mixed/sub-01_${ses}_acq-mixed_meta.json`\n",
    "- (`mri_dataset/sub-01/ses-01/anat/sub-01_ses-01_FLAIR.nii.gz`)\n",
    "\n",
    "The `sub-01_${ses}_acq-mixed_meta.json`-files contain information about repetition times and echo times for both the IR and SE images, and are created as part of the DICOM-conversion process. See section [DICOM conversion](#DICOM-conversion) for details on the conversion from DICOM to Nifti. \n",
    "Note that the FLAIR-image is only used for supporting the FreeSurfer `recon-all` pipeline, and is not strictly necessary.\n",
    "\n",
    "## Executing pipeline\n",
    "Asssuming that all data dependencies exist, the easiest way to run the pipeline for a given subject, is to execute\n",
    "```bash\n",
    "pixi run snakemake -p -c 'all'\n",
    "```\n",
    "which uses Snakemake to figure out the necessary rules to run, and executes them. More details on the processing steps are given below.\n",
    "**NB**: If you do not have access to FreeSurfer or Greedy on your computer, snakemake may be configured to run these steps in a Singularity container, if you add the option `--profile profile` to the snakemake-call. This requires you to have FreeSurfer license file located in the root directory.\n",
    "\n",
    "\n",
    "## Pipeline description\n",
    "\n",
    "### Running FreeSurfer\n",
    "FreeSurfer is used to create a base segmentation of the brain, which in turn is extrapolated to the subarachnoid space and ventricles. FreeSurfer may be run by:\n",
    "```bash\n",
    "recon-all -all  \\\n",
    "    -s sub-01 \\\n",
    "    -sd mri_processed_data/freesurfer \\\n",
    "    -FLAIR mri_dataset/sub-01/ses-01/anat/sub-01_ses-01_FLAIR.nii.gz \\\n",
    "    -FLAIRpial \\\n",
    "    -parallel \n",
    "```\n",
    "**PS**: This step may take somewhere between a few hours to a day, depending on your computer and the image quality . For the purpose of extrapolating segments, you could also consider to use the much faster deep-learning-based `FastSurfer`, which is a drop-in replacement for FreeSurfer.\n",
    "Any potential differences between the segmentations should (probably) have minimal impact for the analysis of the mixed-article.\n",
    "\n",
    "### Estimating $T_1$-times.\n",
    "The $T_1$-maps of the mixed sequence are estimated by comparing the voxelwise ratio of the signal intenstities to a look-up table. The command to generate the mixed T1maps is\n",
    "\n",
    "```bash\n",
    "gmri2fem mri mixed-t1map \\\n",
    "    --SE mri_dataset/sub-01/$ses/mixed/sub-01_${ses}_acq-mixed_SE-modulus.nii.gz \\\n",
    "    --IR mri_dataset/sub-01/$ses/mixed/sub-01_${ses}_acq-mixed_IR-corrected-real.nii.gz \\\n",
    "    --meta mri_dataset/sub-01/$ses/mixed/sub-01_${ses}_acq-mixed_meta.json \\\n",
    "    --output mri_dataset/derivatives/sub-01/$ses/sub-01_${ses}_acq-mixed_T1map_raw.nii.gz\n",
    "```\n",
    "\n",
    "For details on how this is done, see (https://github.com/jorgenriseth/gMRI2FEM/blob/f11a9961b3689250d7fd6cf41357dd7d99a53f68/src/gmri2fem/mixed_t1map.py).\n",
    "\n",
    "### Registering to common image space\n",
    "For longitudinal analysis of the images taken of the same subject at different sessions, we need to register them all to a common image space.\n",
    "For this purpose we use the software `greedy` which is bundled with ITK-snap, or can be downloaded separately.\n",
    "We are only interested in registering images for the same subject, and therefore only consider rigid registration between the sessions.\n",
    "As the reference-image we use the pre-contrast $T_1$-weighted image, which is used by FreeSurfer for the original brain segmentation.\n",
    "\n",
    "`greedy` works in a two-step process: First the registration procedure is applied to find the best – in this case, affine – transformation mapping the data from a moving image (the mixed-images) to the fixed image (the $T_1$-weighted image).\n",
    "The transformation is outputted as a separate text-file as a transformation matrix using homogeneneous coordinates.\n",
    "This transformation may in turn be used to \"reslice\" the moving image (and any images aligned with it) into the image space of the target image.\n",
    "\n",
    "For registering the Mixed IR/SE images, we use the following command to register the pre-contrast SE-modulus image to the reference image:\n",
    "```bash\n",
    "greedy -d 3 -a \\\n",
    " -i mri_dataset/sub-01/ses-01/anat/sub-01_$ses-01_T1w.nii.gz \\\n",
    "     mri_dataset/sub-01/ses-01/mixed/sub-01_ses-01_acq-mixed_SE-modulus.nii.gz \\\n",
    " -o mri_processed_data/sub-01/transforms/{subject}_{session}_acq-mixed.mat \\\n",
    " -ia-image-centers \\\n",
    " -dof 6 \\\n",
    " -m NMI\n",
    "```\n",
    "\n",
    "```bash\n",
    "greedy -d\n",
    " -rf mri_dataset/sub-01/ses-01/anat/sub-01_$ses-01_T1w.nii.gz \\\n",
    " -ri NN \\\n",
    " -rm mri_dataset/sub-01/ses-01/mixed/sub-01_ses-01_acq-mixed_SE-modulus.nii.gz \\\n",
    "     mri_processed_data/sub-01/registered/sub-01_ses-01_acq-mixed_SE-modulus_registered.nii.gz\n",
    " -r mri_processed_data/sub-01/transforms/{subject}_{session}_acq-mixed.mat\n",
    "```\n",
    "\n",
    "The SE-modulus images from the remaining sessions are in turn registered to the already registered pre-contrast SE-modulus image by\n",
    "```bash\n",
    "greedy -d 3 -a \\\n",
    " -i mri_processed_data/sub-01/registered/sub-01_ses-01_acq-mixed_SE-modulus_registered.nii.gz \\ \n",
    "     mri_dataset/sub-01/$ses/mixed/sub-01_${ses}_acq-mixed_SE-modulus.nii.gz \\\n",
    " -o mri_processed_data/sub-01/transforms/{subject}_{session}_acq-mixed.mat \\\n",
    " -ia-image-centers \\\n",
    " -dof 6 \\\n",
    " -m NCC 5x5x5\n",
    "```\n",
    "\n",
    "Finally each of the transformations are applied to the corresponding $T_1$-map:\n",
    "```bash\n",
    "greedy -d 3\n",
    " -rf mri_dataset/sub-01/ses-01/anat/sub-01_$ses-01_T1w.nii.gz \\\n",
    " -ri NN \\\n",
    " -rm mri_dataset/derivatives/sub-01/$ses/sub-01_ses-01_acq-mixed_T1map_raw.nii.gz \\\n",
    "     mri_processed_data/sub-01/registered/sub-01_ses-01_acq-mixed_T1map_raw_registered.nii.gz\n",
    " -r mri_processed_data/sub-01/transforms/{subject}_{session}_acq-mixed.mat\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0047cd",
   "metadata": {},
   "source": [
    "## DICOM Conversion\n",
    "\n",
    "We prefer to work with Nifti-images over DICOM-images due to concerns related to anonymization, storage effieciency, generalizability, and simplicity.\n",
    "Note that due to differences between project structure, MRI-machine vendor etc., this procedure is specific to our project, and might not be directly applicable for a different project. We still include a description of it for transparency, and for use as a starting point for other projects.\n",
    "\n",
    "Most DICOM-images, including the $T_1$-weighted and FLAIR images, may safely be  converted from Enhanced DICOM format to Nifti using the tool `dcm2niix` [https://github.com/rordenlab/dcm2niix].\n",
    "For the Mixed IR/SE-sequence, however, it converts the data in an inconcistent way, where it ocasionally outputs all six volumes as expected, but at other times, it outputs fewer number of images where some of them might contain two volumes as one. \n",
    "We have therefore written a custom script for converting mixed-sequences from DICOM to Nifti.\n",
    "The script is available on (https://github.com/jorgenriseth/gMRI2FEM/blob/f11a9961b3689250d7fd6cf41357dd7d99a53f68/src/gmri2fem/mixed_dicom.py), and may be called \n",
    "as follows.\n",
    "\n",
    "```bash\n",
    "gmri2fem dcm2nii-mixed --subvolume IR-corrected-real --subvolume SE-modulus \\\n",
    "    path/to/dicom/file/for/subject/session/IM_XXXX \\\n",
    "    mri_dataset/$subject/$session/mixed/${subject}_${session}_acq-mixed\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
