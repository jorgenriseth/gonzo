{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e3281bf-cdc8-40d7-a19c-2cbf76a5e9b6",
   "metadata": {},
   "source": [
    "# DICOM-extraction\n",
    "This notebook outlines the procedure for extracting the desired MR-sequences from Philips' enhanced DICOM format to Niftii. The DICOM-files are not included, but we still provide this notebook for transparency. The MRI-data were located within it's own folder in the `mri_dataset`-directory, labeled `sourcedata`, according to a structure `sourcedata/sub-XX/ses-XX/YYYY_MM_DD/{SESSION ID}/DICOM_A_B_{SEQUENCE_LABEL}/DICOM/IM_000X`. \n",
    "At various levels in the aformentioned path-three, there might also be additional files or directories that we want to ignore.\n",
    "\n",
    "There are 7 different types of MRI-sequences included in this dataset:\n",
    "- T1w: All sessions\n",
    "- LookLocker: All sessions\n",
    "- Mixed: All sessions\n",
    "- FLAIR: Pre-contrast only\n",
    "- T2w: Pre-contrast only\n",
    "- DTI dynamic: Pre-contrast only\n",
    "- DTI Top-Up Prescan: Pre-contrast only\n",
    "\n",
    "All of the sequences except the Mixed IR-SE sequence is converted from DICOM to Nifti using `dcm2niix`. For further details on the volume conversion from the mixed sequence conversion, see ()[] or the script `extract_mixed_sequence.py`.\n",
    "The Look-Locker sequence if further manipulated to include all 14 folumes from different triggering times into a single 4D-volume. See below for further details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43a6f7d-e065-4cf7-a2e9-fb54e15cd964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import tempfile\n",
    "import itertools\n",
    "import warnings\n",
    "import re\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "from datetime import date, time, datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import nibabel\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src/gonzo\")\n",
    "\n",
    "from gmri2fem.mixed_dicom import dcm2nii_mixed\n",
    "from loguru import logger\n",
    "logger.disable(\"mixed_dicom\")\n",
    "\n",
    "\n",
    "NUM_SESSIONS = 5\n",
    "mri_dataset = Path(\"../mri_dataset\")\n",
    "private_meta = mri_dataset / \"participants-private.json\"\n",
    "sourcedata = mri_dataset / \"sourcedata\"\n",
    "\n",
    "\n",
    "sub_re = r\"(?P<subject>sub-(control|patient)*\\d{2})\"\n",
    "ses_re = r\"(?P<session>ses-(\\d{2}))\"\n",
    "date_re = r\"(?P<date>\\d{4}_\\d{2}_\\d{2})\"\n",
    "session_id_re = r\"(?P<session_id>\\w+)\"\n",
    "seq_folder_re = r\"(?P<sequence_folder>(DICOM_(?P<scan_id>\\d+)_(?P<series_id>\\d)[_ ](?P<sequence_label>.+)))\"\n",
    "\n",
    "subject_re = re.compile(sub_re)\n",
    "subject_paths = sorted(filter(lambda x: subject_re.match(x.name), sourcedata.glob(\"*\")))\n",
    "subjects = [p.name for p in subject_paths]\n",
    "subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163fc3ae-d956-43c0-a798-bd288f42a005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast_injection_datetime(subject: str, private_meta: Path) -> datetime:\n",
    "    with open(private_meta, \"r\") as f:\n",
    "        injection_time = [\n",
    "            datetime.strptime(entry[\"injection_time\"], \"%Y%m%d_%H%M%S\")\n",
    "            for entry in json.load(f) if entry[\"participant_id\"] == subject \n",
    "        ][0]\n",
    "    return injection_time\n",
    "\n",
    "def sequence_acquisition_date(sequence_path: Path | str) -> datetime:\n",
    "    date_regex = re.compile(\"(?P<year>\\d{4})_(?P<month>\\d{2})_(?P<day>\\d{2})\")\n",
    "    m = date_regex.search(str(sequence_path))\n",
    "    if m is None:\n",
    "        raise ValueError(f\"No date found in '{sequence_path}'\")\n",
    "    return datetime(**{key: int(val) for key, val in m.groupdict().items()}).date()\n",
    "\n",
    "\n",
    "def sequence_acquisition_time_of_day(sequence_outpath: Path) -> time:\n",
    "    sidecars = (sequence_outpath.parent).rglob(f\"*{sequence_outpath.stem}*.json\")\n",
    "    for sidecar in sidecars:        \n",
    "        with open(sidecar, \"r\") as f:\n",
    "            info = json.load(f)\n",
    "        if \"AcquisitionTime\" in info:\n",
    "            return datetime.strptime(info[\"AcquisitionTime\"], \"%H:%M:%S.%f\").time()\n",
    "    raise RuntimeError(f\"Couldn't find sidecar with 'AcquisitionTime' in {sequence_outpath}\")\n",
    "\n",
    "def sequence_acquisition_datetime(sequence_path: Path, sequence_outpath: Path) -> datetime:\n",
    "    return datetime.combine(\n",
    "        sequence_acquisition_date(sequence_path),\n",
    "        sequence_acquisition_time_of_day(sequence_outpath)\n",
    "    )\n",
    "\n",
    "\n",
    "def sequence_seconds_relative_injection(subject, private_meta, sequence_path, sequence_outpath) -> int:\n",
    "    return (\n",
    "        sequence_acquisition_datetime(sequence_path, sequence_outpath)\n",
    "        - contrast_injection_datetime(subject, private_meta)\n",
    "    ).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0642de2f-2a4c-47d2-8ed7-482d2a0f6b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequence:\n",
    "    def __init__(self, name, search_pattern, dtype, label, ignore_pattern=None, sessions=None, overwrite=False, label_shortform=None):\n",
    "        self.name = name\n",
    "        self.search_pattern = search_pattern\n",
    "        if ignore_pattern is None:\n",
    "            self.ignore_pattern = re.compile(\"(NOCONVERT|IGNORE)\")\n",
    "        else:\n",
    "            self.ignore_pattern = ignore_pattern\n",
    "        self.dtype = dtype\n",
    "        self.label = label\n",
    "        self.overwrite = overwrite\n",
    "        if sessions is not None:\n",
    "            self.expected_sessions = sessions\n",
    "        else:\n",
    "            self.expected_sessions = [f\"ses-{idx:02d}\" for idx in range(1, NUM_SESSIONS+1)]\n",
    "        if label_shortform is None:\n",
    "            self.label_shortform = label\n",
    "        else:\n",
    "            self.label_shortform = label_shortform\n",
    "            \n",
    "    def outpath(self, dataset, subject, session):\n",
    "        return dataset / subject / session / self.dtype / f\"{subject}_{session}_{self.label}\"\n",
    "\n",
    "    def convert(self, dicomfile, outpath, additional_args=None):\n",
    "        if additional_args is None:\n",
    "            additional_args = \"\"\n",
    "        outdir, form = outpath.parent, outpath.stem\n",
    "        outdir.mkdir(exist_ok=True, parents=True)\n",
    "        cmd = f\"dcm2niix -f {form} -z y -o '{outdir}' {additional_args} '{dicomfile}' >> /tmp/dcm2niix.txt\"\n",
    "        try:\n",
    "            subprocess.run(cmd, shell=True).check_returncode()\n",
    "        except (ValueError, subprocess.CalledProcessError) as e:\n",
    "            print(str(e))\n",
    "            pass\n",
    "        \n",
    "    def multiple_found_sequences(self, seq_folders):\n",
    "        print(f\"Found multiple directories in {session_folder} matching {seq.search_pattern.pattern}, ignoring.\")\n",
    "        return []\n",
    "        \n",
    "class LookLockerSequence(Sequence):\n",
    "    def convert(self, dicomfile, outpath):\n",
    "        outdir, form = outpath.parent, outpath.stem\n",
    "        outdir.mkdir(exist_ok=True, parents=True)\n",
    "        with tempfile.TemporaryDirectory(prefix=outpath.stem) as tmpdir:\n",
    "            tmppath = Path(tmpdir)\n",
    "            super().convert(dicomfile, tmppath / \"ll_split\")\n",
    "            timestamp_re = re.compile(\"ll_split_t(?P<timestamp>\\d+).json\")\n",
    "            groups = [timestamp_re.match(p.name) for p in tmppath.glob(\"*.json\")]\n",
    "            time_ms = sorted([int(g[\"timestamp\"]) for g in groups])\n",
    "            nii_files = [tmppath / f\"ll_split_t{t}.nii.gz\" for t in time_ms]\n",
    "            example_nii = nibabel.nifti1.load(nii_files[0])\n",
    "            affine = example_nii.affine\n",
    "            D = np.empty((*example_nii.shape, len(nii_files)), dtype=np.single)\n",
    "            for idx, nii in enumerate(nii_files):\n",
    "                D[..., idx] = nibabel.nifti1.load(nii).get_fdata(dtype=np.single)\n",
    "            shutil.copy(tmppath / f\"ll_split_t{time_ms[0]}.json\", outpath.with_suffix(\".json\"))\n",
    "\n",
    "        \n",
    "        np.savetxt(outpath.with_name(outpath.stem + \"_trigger_times.txt\"), time_ms)\n",
    "        nibabel.nifti1.save(\n",
    "            nibabel.nifti1.Nifti1Image(D, affine),\n",
    "            outpath.with_suffix(\".nii.gz\")\n",
    "        )\n",
    "        \n",
    "class MixedSequence(Sequence):\n",
    "    def convert(self, dicomfile, outpath):\n",
    "        outdir, form = outpath.parent, outpath.stem\n",
    "        outdir.mkdir(exist_ok=True, parents=True)\n",
    "        IR_out = outpath.with_name(outpath.stem + \"_IR-corrected-real\")        \n",
    "        SE_out = outpath.with_name(outpath.stem + \"_SE-modulus\")\n",
    "        T1_out = outpath.with_name(outpath.stem + \"_T1map_scanner\")\n",
    "\n",
    "        \n",
    "        IR_data, SE_data, T1_data = dcm2nii_mixed(next(dicomfile.rglob(\"IM_*\")), [\"IR-corrected-real\", \"SE-modulus\", \"T1map-scanner\"])\n",
    "        nibabel.nifti1.save(IR_data[\"nifti\"], IR_out.with_suffix(\".nii.gz\"))\n",
    "        nibabel.nifti1.save(SE_data[\"nifti\"], SE_out.with_suffix(\".nii.gz\"))\n",
    "        nibabel.nifti1.save(T1_data[\"nifti\"], T1_out.with_suffix(\".nii.gz\"))\n",
    "        print(T1_data)\n",
    "                                                                         \n",
    "        meta = {\n",
    "            \"TR_SE\": SE_data[\"descrip\"][\"TR\"],\n",
    "            \"TE\": SE_data[\"descrip\"][\"TE\"],\n",
    "            \"TR_IR\": IR_data[\"descrip\"][\"TR\"],\n",
    "            \"TI\": IR_data[\"descrip\"][\"TI\"],\n",
    "        }\n",
    "        with open(IR_out.parent / f\"{form}_meta.json\", \"w\") as f:\n",
    "            json.dump(meta, f)\n",
    "\n",
    "        try:\n",
    "            cmd = f\"dcm2niix -w 0 --terse -b o -f '{form}' -o '{outdir}' '{dicomfile}' >> /tmp/dcm2niix.txt \"\n",
    "            subprocess.run(cmd, shell=True).check_returncode()\n",
    "        except (ValueError, subprocess.CalledProcessError) as e:\n",
    "            print(str(e))\n",
    "            pass\n",
    "        \n",
    "    def multiple_sequences(self, seq_folders):\n",
    "        new_folders = list(filter(lambda p: re.search(\"DelRec\", str(p)), seq_folders))\n",
    "        if len(new_folders) == 0:\n",
    "            print(f\"Found multiple folders matching {self.regex.pattern}, but none containing 'DelRec': {seq_folders}\")\n",
    "        elif len(new_folders) > 1:\n",
    "            print(f\"Found multiple folders matching {self.regex.pattern} and contatining 'DelRec': {seq_folders}. Ignoring.\")\n",
    "            return []\n",
    "        return new_folders\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1234ff24-807c-441e-87dc-2b78825b90e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = True\n",
    "sequences = [\n",
    "    Sequence(\n",
    "        name=\"T1w\",\n",
    "        search_pattern=re.compile(\"T1_3D\"),\n",
    "        dtype=\"anat\",\n",
    "        label=\"T1w\",\n",
    "        overwrite=overwrite\n",
    "    ),\n",
    "    Sequence(\n",
    "        name=\"T2w\",\n",
    "        search_pattern=re.compile(\"DICOM_\\d+_1.*(TE565|T2W).*\"),\n",
    "        dtype=\"anat\",\n",
    "        label=\"T2w\",\n",
    "        overwrite=overwrite,\n",
    "        sessions=[\"ses-01\"]\n",
    "    ),\n",
    "    Sequence(\n",
    "        name=\"FLAIR\",\n",
    "        search_pattern=re.compile(\".*FLAIR[_ ]3D.*\"),\n",
    "        dtype=\"anat\",\n",
    "        label=\"FLAIR\",\n",
    "        overwrite=overwrite,\n",
    "        sessions=[\"ses-01\"]\n",
    "    ),\n",
    "    Sequence(\n",
    "        name=\"dDTI\",\n",
    "        search_pattern = re.compile(\".*DTI.*dynamisk.*\"),\n",
    "        dtype=\"dwi\",\n",
    "        label=\"acq-multiband_sense_dir-AP_DTI\",\n",
    "        label_shortform=\"dDTI\",\n",
    "        overwrite=overwrite,\n",
    "        sessions=[\"ses-01\"]\n",
    "    ),\n",
    "    Sequence(\n",
    "        name=\"dDTI-Topup\",\n",
    "        search_pattern = re.compile(\".*DTI.*(Top-Up|top-up).*\"),\n",
    "        dtype=\"dwi\",\n",
    "        label=\"acq-multiband_sense_dir-PA_b0\",\n",
    "        label_shortform=\"dDTI-prescan\",\n",
    "        overwrite=overwrite,\n",
    "        sessions=[\"ses-01\"]\n",
    "    ),\n",
    "    MixedSequence(\n",
    "        name=\"Mixed\",\n",
    "        search_pattern = re.compile(\"DICOM_\\d+_\\d.*Mixed.*\"),\n",
    "        dtype=\"mixed\",\n",
    "        label=\"acq-mixed\",\n",
    "        label_shortform=\"mixed\",\n",
    "        overwrite=True\n",
    "    ),\n",
    "    LookLockerSequence(\n",
    "        name=\"LookLocker\",\n",
    "        search_pattern = re.compile(\"DICOM_\\d+_3.*(LookLocker|2beatpause)\"),\n",
    "        dtype=\"anat\",\n",
    "        label=\"acq-looklocker_IRT1\",\n",
    "        label_shortform=\"looklocker\",\n",
    "        overwrite=overwrite\n",
    "    ),\n",
    "]\n",
    "date_regex = re.compile(date_re)\n",
    "seq_folder_regex = re.compile(seq_folder_re)\n",
    "sessions = [f\"ses-{j+1:02d}\" for j in range(NUM_SESSIONS)]\n",
    "timetable_records = []\n",
    "for subject in subjects:\n",
    "    print(\"=\" * 40, subject, \"=\" * 40)\n",
    "    \n",
    "    # Ensure the subjects sourcedata exsists\n",
    "    subject_path = (sourcedata / subject)\n",
    "    if not (sourcedata / subject).exists():\n",
    "        print(f\"Missing subject folder {sourcedata/subject}.\")\n",
    "        continue\n",
    "    for session in sessions:\n",
    "        # Ensure sourcedata of given session exists\n",
    "        session_path = subject_path / session\n",
    "        if not session_path.exists():\n",
    "            print(f\"Missing session folder {session_path}.\")\n",
    "            continue\n",
    "\n",
    "        # Ensure session has the expected directory structure, and find the date\n",
    "        datefolders = sorted(filter(lambda x: date_regex.match(x.name), session_path.iterdir()))\n",
    "        assert len(datefolders) == 1, f\"Session should contain a single date-folder, found {list(session_path.iterdir())}. Choosing first: {datefolders[0]}\"\n",
    "        datefolder = datefolders[0]\n",
    "        session_date = datetime.strptime(datefolder.name, \"%Y_%m_%d\").date()\n",
    "\n",
    "        \n",
    "        # Uncover cases where several scans were performed during the same session\n",
    "        session_folders = sorted(datefolder.glob(\"*\"))\n",
    "        if len(session_folders)  == 0:\n",
    "            print(f\"Found no session-id folder in {datefolder}\")\n",
    "            continue\n",
    "        elif len(session_folders) > 1:\n",
    "            print(f\"Found several session-id folders in {datefolder}: {session_folders}. Choosing first: {session_folders[0]}\")\n",
    "        session_folder = session_folders[0]\n",
    "        all_seq_folders = [p for p in sorted(filter(lambda x: seq_folder_regex.match(x.name), session_folder.glob(\"*\")))]\n",
    "\n",
    "        for seq in sequences:\n",
    "            # Check if the output folder already contains files with desired output pattern, and optionally delete.\n",
    "            seq_out = seq.outpath(mri_dataset, subject, session)\n",
    "            seq_match_in_target = sorted(\n",
    "                filter(\n",
    "                    lambda x: re.match(f\"{seq_out.stem}(.*)\\.(nii\\.gz|json)\", x.name) is not None,\n",
    "                    seq_out.parent.glob(\"*\")\n",
    "                )\n",
    "            )\n",
    "            if len(seq_match_in_target) > 0:\n",
    "                if not seq.overwrite:\n",
    "                    continue\n",
    "                else:\n",
    "                    for file in seq_match_in_target:\n",
    "                        file.unlink()\n",
    "\n",
    "            \n",
    "            # Uncover either missing or multiple sequences matching pattern to investigate potential\n",
    "            # data error, or if the regex needs to be adjusted.\n",
    "            seq_folders = [\n",
    "                folder for folder in all_seq_folders if (\n",
    "                    seq.search_pattern.search(folder.name) and (not seq.ignore_pattern.search(folder.name))\n",
    "                )\n",
    "            ]\n",
    "            if len(seq_folders) == 0:\n",
    "                if session in seq.expected_sessions:\n",
    "                    print(f\"Couldn't find pattern {seq.search_pattern.pattern} in {session_folder}\")\n",
    "                continue\n",
    "            elif len(seq_folders) > 1:\n",
    "                print(f\"Found mulitple directories in {session_folder} matching {seq.search_pattern.pattern}, ignoring.\")\n",
    "                continue\n",
    "            seq_folder = seq_folders[0]\n",
    "            if session not in seq.expected_sessions:\n",
    "                print(f\"Found sequence {seq.name} with pattern {seq.search_pattern} in unexpected session {session}: Extracting to ses-01\")\n",
    "                # Check if the output folder already contains files with desired output pattern        \n",
    "                seq_out = seq.outpath(mri_dataset, subject, \"ses-01\")\n",
    "            seq.convert(seq_folder , seq_out)\n",
    "\n",
    "            relative_time = sequence_seconds_relative_injection(subject, private_meta, seq_folder, seq_out)\n",
    "            timetable_record = {\n",
    "                \"subject\": subject,\n",
    "                \"session\": session,\n",
    "                \"sequence_label\": seq.label_shortform,\n",
    "                \"acquisition_relative_injection\": relative_time\n",
    "            }\n",
    "            timetable_records.append(timetable_record)\n",
    "\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91c6e2e-7ea2-4135-bc23-a01a301c7912",
   "metadata": {},
   "outputs": [],
   "source": [
    "dframe = pd.DataFrame.from_records(timetable_records).sort_values(by=[\"subject\", \"sequence_label\", \"session\", \"acquisition_relative_injection\"])\n",
    "if (mri_dataset / \"timetable.tsv\").exists():\n",
    "    answer = input(\"Timetable already exists. Overwrite?\")\n",
    "    if answer.lower() in [\"y\", \"yes\"]:\n",
    "        dframe.to_csv(mri_dataset / \"timetable.tsv\", index=False, sep=\"\\t\")\n",
    "else:\n",
    "    dframe.to_csv(mri_dataset / \"timetable.tsv\", index=False, sep=\"\\t\")\n",
    "\n",
    "pd.read_csv(mri_dataset / \"timetable.tsv\", sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
